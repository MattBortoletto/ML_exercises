{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clothes Classification with Neural Networks\n",
    "\n",
    "In this notebook we are going to explore the Neural Networks for image classification. We are going to use the same dataset of the SVM notebook: Fashion MNIST (https://pravarmahajan.github.io/fashion/), a dataset of small images of clothes and accessories.\n",
    "\n",
    "The dataset labels are the following:\n",
    "\n",
    "| Label | Description |\n",
    "| --- | --- |\n",
    "| 0 | T-shirt/top |\n",
    "| 1 | Trouser |\n",
    "| 2 | Pullover |\n",
    "| 3 | Dress |\n",
    "| 4 | Coat |\n",
    "| 5 | Sandal |\n",
    "| 6 | Shirt |\n",
    "| 7 | Sneaker |\n",
    "| 8 | Bag |\n",
    "| 9 | Ankle boot |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn version:  0.21.2\n"
     ]
    }
   ],
   "source": [
    "#load the required packages and check Scikit-learn version\n",
    "\n",
    "%matplotlib inline  \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "print ('scikit-learn version: ', sklearn.__version__)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to load Fashion MNIST dataset from disk\n",
    "def load_mnist(path, kind='train'):\n",
    "    import os\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "    labels_path = os.path.join(path, '%s-labels-idx1-ubyte.gz' % kind)\n",
    "    images_path = os.path.join(path, '%s-images-idx3-ubyte.gz' % kind)\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,offset=8)\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,offset=16).reshape(len(labels), 784)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO \n",
    "Place a seed for the random generator (you can use your \"numero di matricola\"). Try to change the seed to see the impact of the randomization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = 1146169 #PLACE YOUR ID\n",
    "np.random.seed(ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the MNIST dataset: 60000\n"
     ]
    }
   ],
   "source": [
    "#load the MNIST dataset and let's normalize the features so that each value is in [0,1]\n",
    "X, y = load_mnist(\"data\")\n",
    "print(\"Number of samples in the MNIST dataset:\", X.shape[0])\n",
    "# rescale the data\n",
    "X = X / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now split into training and test. We start with a small training set of 600 samples to reduce computation time. Make sure that each label is present at least 10 times\n",
    "in training frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels in training dataset:  [0 1 2 3 4 5 6 7 8 9]\n",
      "Frequencies in training dataset:  [56 68 60 62 57 58 59 64 59 57]\n"
     ]
    }
   ],
   "source": [
    "#random permute the data and split into training and test taking the first 600\n",
    "#data samples as training and the rests as test\n",
    "permutation = np.random.permutation(X.shape[0])\n",
    "\n",
    "X = X[permutation]\n",
    "y = y[permutation]\n",
    "\n",
    "m_training = 600\n",
    "\n",
    "X_train, X_test = X[:m_training], X[m_training:]\n",
    "y_train, y_test = y[:m_training], y[m_training:]\n",
    "\n",
    "labels, freqs = np.unique(y_train, return_counts=True)\n",
    "print(\"Labels in training dataset: \", labels)\n",
    "print(\"Frequencies in training dataset: \", freqs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for plotting a image and printing the corresponding label\n",
    "def plot_input(X_matrix, labels, index):\n",
    "    print(\"INPUT:\")\n",
    "    plt.imshow(\n",
    "        X_matrix[index].reshape(28,28),\n",
    "        cmap          = plt.cm.gray_r,\n",
    "        interpolation = \"nearest\"\n",
    "    )\n",
    "    plt.show()\n",
    "    print(\"LABEL: %i\"%labels[index])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 9\n",
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 0\n",
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 2\n"
     ]
    }
   ],
   "source": [
    "#let's try the plotting function\n",
    "plot_input(X_train,y_train,10)\n",
    "plot_input(X_test,y_test,100)\n",
    "plot_input(X_test,y_test,10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 1\n",
    "\n",
    "Now use a feed-forward Neural Network for prediction. Use the multi-layer perceptron classifier, with the following parameters: max_iter=300, alpha=1e-4, solver='sgd', tol=1e-4, learning_rate_init=.1, random_state=ID (this last parameter ensures the run is the same even if you run it more than once). The alpha parameter is the regularization term.\n",
    "\n",
    "Then, using the default activation function, pick four or five architectures to consider, with different numbers of hidden layers and different sizes. It is not necessary to create huge neural networks, you can limit to 3 layers and, for each layer, its maximum size can be of 100. Evaluate the architectures you chose using GridSearchCV with cv=5.\n",
    "\n",
    "You can reduce the number of iterations if the running time is too long on your computer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/borto/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR NN\n",
      "\n",
      "Best parameters set found: {'hidden_layer_sizes': (20,)}\n",
      "Score with best parameters: 0.775\n",
      "\n",
      "All scores on the grid: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.524142</td>\n",
       "      <td>0.258791</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>{'hidden_layer_sizes': (10,)}</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.661017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.041442</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997904</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.734440</td>\n",
       "      <td>0.752577</td>\n",
       "      <td>0.896984</td>\n",
       "      <td>0.125446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.533775</td>\n",
       "      <td>0.037931</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>(20,)</td>\n",
       "      <td>{'hidden_layer_sizes': (20,)}</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0.737288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.024430</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.651956</td>\n",
       "      <td>0.033515</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>(40,)</td>\n",
       "      <td>{'hidden_layer_sizes': (40,)}</td>\n",
       "      <td>0.782258</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.720339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.765000</td>\n",
       "      <td>0.030066</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.326769</td>\n",
       "      <td>0.071337</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>(40, 20)</td>\n",
       "      <td>{'hidden_layer_sizes': (40, 20)}</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.739837</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.661017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703333</td>\n",
       "      <td>0.058503</td>\n",
       "      <td>4</td>\n",
       "      <td>0.924370</td>\n",
       "      <td>0.939203</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.751037</td>\n",
       "      <td>0.925773</td>\n",
       "      <td>0.855993</td>\n",
       "      <td>0.090593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.288035</td>\n",
       "      <td>0.098412</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>(40, 30, 20)</td>\n",
       "      <td>{'hidden_layer_sizes': (40, 30, 20)}</td>\n",
       "      <td>0.104839</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.483051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.403333</td>\n",
       "      <td>0.253253</td>\n",
       "      <td>5</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.616352</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.539419</td>\n",
       "      <td>0.103093</td>\n",
       "      <td>0.433618</td>\n",
       "      <td>0.281491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.524142      0.258791         0.000561        0.000022   \n",
       "1       0.533775      0.037931         0.000576        0.000005   \n",
       "2       0.651956      0.033515         0.000692        0.000023   \n",
       "3       0.326769      0.071337         0.000910        0.000166   \n",
       "4       0.288035      0.098412         0.000747        0.000010   \n",
       "\n",
       "  param_hidden_layer_sizes                                params  \\\n",
       "0                    (10,)         {'hidden_layer_sizes': (10,)}   \n",
       "1                    (20,)         {'hidden_layer_sizes': (20,)}   \n",
       "2                    (40,)         {'hidden_layer_sizes': (40,)}   \n",
       "3                 (40, 20)      {'hidden_layer_sizes': (40, 20)}   \n",
       "4             (40, 30, 20)  {'hidden_layer_sizes': (40, 30, 20)}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.758065           0.756098           0.683333           0.661017   \n",
       "1           0.806452           0.780488           0.758333           0.737288   \n",
       "2           0.782258           0.804878           0.741667           0.720339   \n",
       "3           0.750000           0.739837           0.608333           0.661017   \n",
       "4           0.104839           0.609756           0.708333           0.483051   \n",
       "\n",
       "   ...  mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0  ...         0.708333        0.041442                3            1.000000   \n",
       "1  ...         0.775000        0.024430                1            1.000000   \n",
       "2  ...         0.765000        0.030066                2            1.000000   \n",
       "3  ...         0.703333        0.058503                4            0.924370   \n",
       "4  ...         0.403333        0.253253                5            0.107143   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0            0.997904            1.000000            0.734440   \n",
       "1            1.000000            1.000000            1.000000   \n",
       "2            1.000000            1.000000            1.000000   \n",
       "3            0.939203            0.739583            0.751037   \n",
       "4            0.616352            0.802083            0.539419   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.752577          0.896984         0.125446  \n",
       "1            1.000000          1.000000         0.000000  \n",
       "2            1.000000          1.000000         0.000000  \n",
       "3            0.925773          0.855993         0.090593  \n",
       "4            0.103093          0.433618         0.281491  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are sample values but feel free to change them as you like, try to experiment with different sizes!!\n",
    "parameters = {'hidden_layer_sizes': [(10,), (20,), (40,), (40,20,), (40,30,20) ]}\n",
    "\n",
    "mlp = MLPClassifier(max_iter=300, alpha=1e-4, solver='sgd',\n",
    "                    tol=1e-4, random_state=ID,\n",
    "                    learning_rate_init=.1)\n",
    "\n",
    "\n",
    "#ADD YOUR CODE\n",
    "clf = GridSearchCV(estimator=mlp, param_grid=parameters, cv=5, return_train_score=True)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print ('RESULTS FOR NN\\n')\n",
    "\n",
    "print(\"Best parameters set found:\", clf.best_params_)\n",
    "#ADD YOUR CODE\n",
    "\n",
    "print(\"Score with best parameters:\", clf.best_score_)\n",
    "#ADD YOUR CODE\n",
    "\n",
    "print(\"\\nAll scores on the grid: \\n\")\n",
    "#ADD YOUR CODE\n",
    "all_scores = pd.DataFrame(clf.cv_results_)\n",
    "all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO 2\n",
    "\n",
    "Now try also different batch sizes, while keeping the best NN architecture you have found above. Remember that the batch size was previously set to the default value, i.e., min(200, n_samples). \n",
    "Recall that a batch size of 1 corresponds to baseline SGD, while using all the 480 training samples (there are 600 samples but in cross validation with 5 folders we use 1/5 of them for validation at each round) corresponds to standard GD and using a different mini-batch size lies in the middle between the two extreme cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are sample values corresponding to baseline SGD, a reasonable mini-batch size and standard GD\n",
    "# again feel free to change them as you like, try to experiment with different batch sizes!!\n",
    "parameters = {'batch_size': [1, 32, 480]}\n",
    "\n",
    "# need to specify that you would like to use the standard k-fold split otherwise sklearn create splits of different sizes\n",
    "kf = sklearn.model_selection.KFold(n_splits=5)\n",
    "\n",
    "#ADD YOUR CODE\n",
    "\n",
    "# recall to use cv=kf in GridSearchCV parameters to use the k-fold subdivision seen in the lectures\n",
    "\n",
    "#ADD YOUR CODE\n",
    "\n",
    "print ('RESULTS FOR NN\\n')\n",
    "\n",
    "print(\"Best parameters set found:\")\n",
    "#ADD YOUR CODE\n",
    "\n",
    "print(\"Score with best parameters:\")\n",
    "#ADD YOUR CODE\n",
    "\n",
    "print(\"\\nAll scores on the grid:\")\n",
    "#ADD YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 1\n",
    "\n",
    "What do you observe for different architectures and batch sizes? How do the number of layers and their sizes affect the performances? What do you observe for different batch sizes, in particular what happens to the training convergence for different batch sizes (notice that the algorithm could not converge for some batch sizes)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ANSWER TO QUESTION 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO 3\n",
    "\n",
    "Now try also to use different learning rates, while keeping the best NN architecture and batch size you have found above. Plot the learning curves (i.e., the variation of the loss over the steps, you can get it from the loss_curve_ object of sklearn) for the different values of the learning rate . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "lr_list = [10**exp for exp in range(-3,0)]\n",
    "scores = {}\n",
    "\n",
    "#ADD YOUR CODE\n",
    "\n",
    "\n",
    "print ('RESULTS FOR NN\\n')\n",
    "\n",
    "print(\"Best parameters set found:\")\n",
    "#ADD YOUR CODE\n",
    "\n",
    "print(\"Score with best parameters:\")\n",
    "#ADD YOUR CODE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 2\n",
    "\n",
    "Comment about the learning curves (i.e. the variation of the loss over the steps). How does the curve changes for different learning rates in terms of stability and speed of convergence ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ANSWER TO QUESTION 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO 4\n",
    "\n",
    "Now get training and test error for a NN with best parameters (architecture, batch size and learning rate)from above. Plot the learning curve also for this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get training and test error for the best NN model from CV\n",
    "\n",
    "#ADD YOUR CODE\n",
    "best_NN = MLPClassifier(hidden_layer_sizes=(20, ), max_iter=300, alpha=1e-4, solver='sgd',\n",
    "                        tol=1e-4, random_state=ID, learning_rate_init=.1)\n",
    "\n",
    "best_NN.fit(X_train, y_train)\n",
    "\n",
    "training_error = 1 - best_NN.score(X_train,y_train)\n",
    "test_error = 1 - best_NN.score(X_test,y_test)\n",
    "\n",
    "print ('\\nRESULTS FOR BEST NN\\n')\n",
    "\n",
    "print (\"Best NN training error: %f\" % training_error)\n",
    "print (\"Best NN test error: %f\" % test_error)\n",
    "\n",
    "#ADD YOUR CODE FOR PLOTTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More data \n",
    "Now let's do the same but using 5000 (or less if it takes too long on your machine) data points for training. Use the same NN architecture as before, but you can try more if you like and have a powerful computer !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[permutation]\n",
    "y = y[permutation]\n",
    "\n",
    "m_training = 5000\n",
    "\n",
    "X_train, X_test = X[:m_training], X[m_training:]\n",
    "y_train, y_test = y[:m_training], y[m_training:]\n",
    "\n",
    "labels, freqs = np.unique(y_train, return_counts=True)\n",
    "print(\"Labels in training dataset: \", labels)\n",
    "print(\"Frequencies in training dataset: \", freqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 5\n",
    "\n",
    "Now train the NNs with the added data points using the optimum parameters found above. Eventually, feel free to try different architectures if you like. We suggest that you use 'verbose=True' so have an idea of how long it takes to run 1 iteration (eventually reduce also the number of iterations to 50)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use best architecture and params from before\n",
    "\n",
    "#ADD YOUR CODE\n",
    "\n",
    "print ('\\nRESULTS FOR NN\\n')\n",
    "\n",
    "print (\"NN training error: %f\" % training_error)\n",
    "print (\"NN test error: %f\" % test_error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTION 3\n",
    "Compare the train and test errors you got with a large number of samples with the best one you obtained with only 600 data points. Comment about the results you obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ANSWER TO QUESTION 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO 7\n",
    "\n",
    "Plot an example that was missclassified by NN with m=600 training data points and it is now instead correctly classified by NN with m=5000 training data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_prediction = #ADD YOUR CODE\n",
    "large_NN_prediction = #ADD YOUR CODE\n",
    "\n",
    "#ADD YOUR CODE\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO 8\n",
    "\n",
    "Let's plot the weigths of the multi-layer perceptron classifier, for the best NN we get with 600 data points and with 5000 data points. The code is already provided, just fix variable names (e.g., replace mlp ,  mlp_large with your estimators) in order to have it working with your implementation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code is already provided, fix variable names in order to have it working with your implementation\n",
    "\n",
    "print(\"Weights with 600 data points:\")\n",
    "\n",
    "fig, axes = plt.subplots(4, 4)\n",
    "vmin, vmax = mlp.coefs_[0].min(), mlp.coefs_[0].max()\n",
    "for coef, ax in zip(mlp.coefs_[0].T, axes.ravel()):\n",
    "    ax.matshow(coef.reshape(28, 28), cmap=plt.cm.gray, vmin=.5 * vmin,\n",
    "               vmax=.5 * vmax)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Weights with 5000 data points:\")\n",
    "\n",
    "fig, axes = plt.subplots(4, 4)\n",
    "vmin, vmax = mlp_large.coefs_[0].min(), mlp_large.coefs_[0].max()\n",
    "for coef, ax in zip(mlp.coefs_[0].T, axes.ravel()):\n",
    "    ax.matshow(coef.reshape(28, 28), cmap=plt.cm.gray, vmin=.5 * vmin,\n",
    "               vmax=.5 * vmax)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTION 4\n",
    "\n",
    "Describe what do you observe by looking at the weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ANSWER TO QUESTION 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO 9\n",
    "\n",
    "Report the best SVM model and its parameters, you found in the last notebook (or check out the solution on the moodle webpage of the course). Fit it on a few data points and compute its training and test scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_training = 5000\n",
    "\n",
    "X_train, X_test = X[:m_training], X[m_training:2*m_training]\n",
    "y_train, y_test = y[:m_training], y[m_training:2*m_training]\n",
    "\n",
    "# use best parameters found in the SVM notebook, create SVM and perform fitting\n",
    "\n",
    "#ADD YOUR CODE\n",
    "\n",
    "print ('RESULTS FOR SVM')\n",
    "\n",
    "SVM_training_error = #ADD YOUR CODE\n",
    "\n",
    "print(\"Training score SVM:\")\n",
    "print(SVM_training_error)\n",
    "\n",
    "SVM_test_error = #ADD YOUR CODE\n",
    "print(\"Test score SVM:\")\n",
    "print(SVM_test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## QUESTION 5\n",
    "Compare the results of SVM and of NN. Which one would you prefer? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ANSWER TO QUESTION 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
